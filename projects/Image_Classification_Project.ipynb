{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMm2GuP8q7GFd/nOTYVIt5F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cortiz313/Machine-Learning-Class/blob/main/projects/Image_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification Project\n",
        "By: Christian Ortiz and Sejal Nathu-Hari\n",
        "\n",
        "Note: Just as we did for Project 2, we collaborated over Zoom for the entirety of the project, working through the assignment together. There was no separation in the work, we added to it and worked on it all together"
      ],
      "metadata": {
        "id": "IYhf9hzaBv2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Reading and Observing the Data"
      ],
      "metadata": {
        "id": "9Q-FfF6jDuNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will read the CIFAR10 dataset into variables, and take a look at the shape and description of the data"
      ],
      "metadata": {
        "id": "ZzKwlvqADyHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Keras library from TensorFlow\n",
        "from tensorflow import keras\n",
        "\n",
        "# Importing train_test_split to split the dataset into training and testing subsets, or training and validation sets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "_yEpAHXDs3Kt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 dataset and assign to variables\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "sOwqKKtLtLvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of each variable\n",
        "print(\"Shape of train_images:\", train_images.shape)\n",
        "print(\"Shape of train_labels:\", train_labels.shape)\n",
        "print(\"Shape of test_images:\", test_images.shape)\n",
        "print(\"Shape of test_labels:\", test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6bBDLyTD-bb",
        "outputId": "0590ac27-4d7b-4ded-a568-6a5588184e00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_images: (50000, 32, 32, 3)\n",
            "Shape of train_labels: (50000, 1)\n",
            "Shape of test_images: (10000, 32, 32, 3)\n",
            "Shape of test_labels: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the training data has 50,000 images of shape 32,32,3 and the test data has 10,000 images of size 32,32,3 as well. The labels, of course, have the same number of images, with only a single column corresponding to the label of the image."
      ],
      "metadata": {
        "id": "k1WOweh2Yxsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Splitting and Manipulating the Data"
      ],
      "metadata": {
        "id": "ZvFR_4qiGgeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will split the training set into training and validation sets in order to fit our model later"
      ],
      "metadata": {
        "id": "afe6C2OvEqOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the training data into training and validation sets. 80% in the training sets and 20% in the validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tSWVzQ1ltN3h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we look at the shapes of the image sets to observe the split"
      ],
      "metadata": {
        "id": "E2pkaAfGFkb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roVwcNIcFDBK",
        "outputId": "eb23eec4-2b4e-490c-a907-8f7c6fd0c93f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDbyrdR1Fano",
        "outputId": "80403ae8-e1e6-48fd-dd70-a05e0c9c6a4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, we find 40,000 images in the train set and 10,000 in the validation set."
      ],
      "metadata": {
        "id": "dH-mPnDUYoLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will normalize the pixel values, so instead of being from 0 to 255, they are from 0 to 1"
      ],
      "metadata": {
        "id": "IhRgqyB-GV1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1 for training and testing images\n",
        "train_images, test_images = train_images / 255., test_images / 255."
      ],
      "metadata": {
        "id": "6Tg3ArzjFBqA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize validation images\n",
        "val_images = val_images / 255."
      ],
      "metadata": {
        "id": "pdejawAYGGeG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to check the values briefly to make sure they are normalized, let's look at the values of the first image in this train_images array"
      ],
      "metadata": {
        "id": "03RjYNwOG1HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0]"
      ],
      "metadata": {
        "id": "ZhpbLPpYE9ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Creating our CNN"
      ],
      "metadata": {
        "id": "xKmzM0JHHRKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will define the architecture of the model, adding several layers that will help us to classify the CIFAR-10 images"
      ],
      "metadata": {
        "id": "GaT84uLgHXB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = keras.Sequential([\n",
        "    # Add a convolutional layer with 32 filters, each of size 3x3 with ReLU activation\n",
        "    # Set the input shape to be 32x32 pixels with 3 color channels, because that is the shape of the CIFAR-10 images as we saw earlier\n",
        "    keras.layers.Conv2D(32, kernel_size=(3,3) ,  activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "    \n",
        "    # Add a max pooling layer with a pool size of 2x2\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Add another convolutional layer with 64 filters, each of size 3x3 with ReLU activation\n",
        "    keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"),\n",
        "    \n",
        "    # Add another max pooling layer with a pool size of 2x2\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Flatten the output from the previous layer\n",
        "    keras.layers.Flatten(),\n",
        "    \n",
        "    # Add a fully connected dense layer with 64 units and ReLU activation\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    \n",
        "    # Add a fully connected dense layer with 10 units (one for each class)\n",
        "    # We tried adding the activation parameter here, but it led to worst results in accuracy\n",
        "    keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "31srW9wGtQ7X"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this line displays the layers in the model and the number of parameters in each layer\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHlc3KszM6qF",
        "outputId": "d0344547-564e-4984-fbeb-dada77d59745"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                147520    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167,562\n",
            "Trainable params: 167,562\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Compiling the Model"
      ],
      "metadata": {
        "id": "UybGzX-jOh6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So initially, we were compiling the model as seen below, but we were getting very low accuracy on both the validation data and the test data. So after some research, we found that the SparseCategoricalCrossentropy would work better for our data. Our classification problem in this project involves multi-class classification, i.e. classifying the images into one of ten possible categories, so it makes sense to use a loss function that is specifically designed for multi-class classification tasks, which Sparse Categorical Crossentropy is made for.\n",
        "Binary crossentropy is used when there are only two possible classes to classify. \n",
        "\n",
        "<br>\n",
        "\n",
        "The choice of using the \"adam\" optimizer was because we found that it is a more advanced optimization algortihm, and combines the benefits of two other popular algos, one being RMSProp which we use here, and the other being AdaGrad. We tested it out, and found that we had a higher accuracy on both the validation and the test data, so we kept it."
      ],
      "metadata": {
        "id": "dAIKDWZJOk4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "#                 loss='binary_crossentropy',\n",
        "#                 metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ep23r5WYtTUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the adam optimizer\n",
        "model.compile(optimizer=\"adam\",\n",
        "              # Sparse categorical crossentropy is used as the loss function, since we are dealing with a multiclass classification problem.\n",
        "              # We set from_logits=True because our last layer does not have a softmax activation function\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              # We use accuracy as the metric to monitor during training\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-TJ_lHCp7fDh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Fitting the Model"
      ],
      "metadata": {
        "id": "1z_puCT_Rh2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we fit the model. We tried a different number of epochs (5,10,20), and different batch sizes (32,256), and we found 10 epochs and a batch size of 256 gave us the best result. "
      ],
      "metadata": {
        "id": "6Vp-n-rwTzUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set and validate it on the validation set for 20 epochs, using a batch size of 32.\n",
        "hist = model.fit(train_images, train_labels, validation_data=(val_images, val_labels), epochs=10, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9nZoz-QPKY3",
        "outputId": "a4a2dad4-bb44-47ee-9adf-1e7abdf215e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.7549 - accuracy: 0.7388 - val_loss: 0.9096 - val_accuracy: 0.6854\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7242 - accuracy: 0.7499 - val_loss: 0.8988 - val_accuracy: 0.6872\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7107 - accuracy: 0.7560 - val_loss: 0.8944 - val_accuracy: 0.6912\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6981 - accuracy: 0.7585 - val_loss: 0.8855 - val_accuracy: 0.6935\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6853 - accuracy: 0.7638 - val_loss: 0.9159 - val_accuracy: 0.6858\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6737 - accuracy: 0.7684 - val_loss: 0.8876 - val_accuracy: 0.6971\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.6580 - accuracy: 0.7733 - val_loss: 0.8826 - val_accuracy: 0.6998\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6454 - accuracy: 0.7775 - val_loss: 0.8926 - val_accuracy: 0.6935\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6321 - accuracy: 0.7817 - val_loss: 0.8952 - val_accuracy: 0.6981\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6185 - accuracy: 0.7866 - val_loss: 0.8912 - val_accuracy: 0.6976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Printing the Accuracy on the Test Data"
      ],
      "metadata": {
        "id": "cGZ4tgryRjjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model's accuracy on the test set\n",
        "acc_score = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(\"Accuracy: \", acc_score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3enxLHVtTz_",
        "outputId": "16908747-7ed4-4cb8-9954-b674d0b92444"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9144 - accuracy: 0.6956\n",
            "Accuracy:  0.6955999732017517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were able to achieve a 69.6% accuracy score on our test data, which was the best score we were able to get from our tweaks. On other tests, we hovered around 65-67%.\n",
        "\n",
        "<br>\n",
        "\n",
        "Overall, although we know with more advanced methods you can probably get a higher score, we are happy with the score we were able to achieve. "
      ],
      "metadata": {
        "id": "-YOs2tRqW6S2"
      }
    }
  ]
}